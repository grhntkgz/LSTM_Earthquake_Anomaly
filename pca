import pandas as pd
import numpy as np
from scipy.signal import welch
from scipy.stats import skew, kurtosis
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import pywt

# Wavelet Entropy hesaplama fonksiyonu
def calculate_wavelet_entropy(coeffs):
    total_energy = sum(np.sum(c ** 2) for c in coeffs)
    entropy = -sum(np.sum(c ** 2) / total_energy * np.log(np.sum(c ** 2) / total_energy) for c in coeffs)
    return entropy

# Function to calculate spectral features
def calculate_spectral_features(data, fs, nperseg):
    frequencies, psd = welch(data, fs=fs, nperseg=nperseg)
    spectral_centroid = np.sum(frequencies * psd) / np.sum(psd)
    spectral_bandwidth = np.sqrt(np.sum(((frequencies - spectral_centroid) ** 2) * psd) / np.sum(psd))
    spectral_flatness = np.exp(np.mean(np.log(psd))) / np.mean(psd)
    cumulative_energy = np.cumsum(psd)
    total_energy = cumulative_energy[-1]
    roll_off = frequencies[np.where(cumulative_energy >= 0.75 * total_energy)[0][0]]
    peak_psd_index = np.argmax(psd)
    peak_psd_frequency = frequencies[peak_psd_index]
    peak_psd_energy = psd[peak_psd_index]

    spectral_entropy = -np.sum((psd / np.sum(psd)) * np.log(psd / np.sum(psd) + np.finfo(float).eps))
    spectral_kurtosis = kurtosis(psd)
    spectral_slope = np.polyfit(frequencies, psd, 1)[0]

    # Bandwidth içerisindeki frekanslar
    lower_bound = spectral_centroid - spectral_bandwidth / 2
    upper_bound = spectral_centroid + spectral_bandwidth / 2
    bandwidth_mask = (frequencies >= lower_bound) & (frequencies <= upper_bound)
    bandwidth_energies = psd[bandwidth_mask]

    # Bandwidth içerisindeki frekansların ortalama enerjisi
    bandwidth_avg_energy = np.mean(bandwidth_energies)

    # Yeni özellik: Frekans Bandı Enerji Oranı
    low_freq_band = (frequencies >= 0) & (frequencies <= 3)  # 0-5 Hz düşük frekans bandı
    high_freq_band = (frequencies > 3) & (frequencies <= 50)  # 5-50 Hz yüksek frekans bandı

    low_freq_energy = np.sum(psd[low_freq_band])
    high_freq_energy = np.sum(psd[high_freq_band])

    if high_freq_energy == 0:
        high_freq_energy = 1e-10  # Bölme hatalarını önlemek için küçük bir sabit ekleyin

    freq_band_energy_ratio = low_freq_energy / high_freq_energy

    # Wavelet Entropy hesaplama
    coeffs = pywt.wavedec(data, 'db4', level=3)
    wavelet_entropy = calculate_wavelet_entropy(coeffs[1:])

    return (
        spectral_centroid, spectral_bandwidth, spectral_flatness, roll_off,
        peak_psd_frequency, peak_psd_energy, spectral_entropy, spectral_kurtosis,
        spectral_slope, bandwidth_avg_energy, freq_band_energy_ratio, wavelet_entropy
    )

# Function to calculate temporal features
def calculate_temporal_features(data):
    crest_factor = np.max(np.abs(data)) / np.sqrt(np.mean(data ** 2))
    energy = np.sum(data ** 2)
    skewness_value = skew(data)
    kurtosis_value = kurtosis(data)
    zero_crossing_rate = ((data[:-1] * data[1:]) < 0).sum() / len(data)
    return crest_factor, energy, skewness_value, kurtosis_value, zero_crossing_rate

# Function to perform PCA
def apply_pca(features, n_components=3):
    pca = PCA(n_components=n_components)
    pca_result = pca.fit_transform(features)
    explained_variance = pca.explained_variance_ratio_
    components = pca.components_
    return pca_result, explained_variance, components

# Main function with PCA for specified intervals
def main_with_pca_by_intervals():
    # Load the CSV data
    file_path = 'veri/BURSA DEPREMİ/G-combined_bursa_1.csv'  # Dosya yolu buradan belirlenir.
    data = pd.read_csv(file_path)
    fs = 100  # Sampling frequency
    time = data.index / fs

    # Use the first column as the acceleration data
    acceleration_data = data.iloc[:, 0]

    # Plot acceleration vs time graph
    plt.figure(figsize=(10, 6))
    plt.plot(time, acceleration_data)
    plt.xlabel('Time (seconds)')
    plt.ylabel('Acceleration (g)')
    plt.title('Acceleration Time Series')
    plt.grid(True)
    plt.show()

    # Parameters for Welch's method and step size
    nperseg = 128  # Welch's method parameter
    step_size = 5  # Window step size in seconds

    intervals = []

    # Get intervals from user input
    while True:
        try:
            start_time = float(input("Başlangıç zamanını girin (saniye): "))
            end_time = float(input("Bitiş zamanını girin (saniye): "))
            label = input("Bu aralık için etiketi girin: ")
            intervals.append((start_time, end_time, label))

            more_intervals = input("Başka bir aralık eklemek ister misiniz? (e/h): ")
            if more_intervals.lower() != 'e':
                break
        except ValueError:
            print("Geçersiz giriş! Lütfen geçerli bir sayı girin.")

    # Loop through each interval
    for interval in intervals:
        start_time, end_time, label = interval
        print(f"\nInterval: {start_time} to {end_time} seconds (Etiket: {label})")

        # Select the data within the interval
        start_sample = int(start_time * fs)
        end_sample = int(min(end_time * fs, len(acceleration_data)))

        selected_data = acceleration_data[start_sample:end_sample]

        # Sliding window feature calculation
        window_results = []
        for start_time in np.arange(start_time, end_time, step_size):
            start_sample = int(start_time * fs)
            end_sample = int(min((start_time + step_size) * fs, len(acceleration_data)))

            if end_sample > len(acceleration_data):
                break

            selected_data_window = acceleration_data[start_sample:end_sample]

            # Calculate spectral and temporal features
            spectral_features = calculate_spectral_features(selected_data_window, fs, nperseg=nperseg)
            temporal_features = calculate_temporal_features(selected_data_window)

            result = {
                "Başlangıç Zamanı (saniye)": start_time,
                "Bitiş Zamanı (saniye)": end_sample / fs,
                "Spectral Centroid (Hz)": spectral_features[0],
                "Spectral Bandwidth (Hz)": spectral_features[1],
                "Spectral Flatness": spectral_features[2],
                "Spectral Roll-off Frequency (Hz)": spectral_features[3],
                "Peak PSD Frequency (Hz)": spectral_features[4],
                "Peak PSD Energy": spectral_features[5],
                "Spectral Entropy": spectral_features[6],
                "Spectral Kurtosis": spectral_features[7],
                "Spectral Slope": spectral_features[8],
                "Crest Factor": temporal_features[0],
                "Energy": temporal_features[1],
                "Skewness": temporal_features[2],
                "Kurtosis": temporal_features[3],
                "Zero-Crossing Rate": temporal_features[4],
                "Bandwidth Average Energy": spectral_features[9],
                "Frequency Band Energy Ratio": spectral_features[10],
                "Wavelet Entropy": spectral_features[11]
            }
            window_results.append(result)

        # Convert results to DataFrame
        results_df = pd.DataFrame(window_results)

        # Extract features for PCA
        feature_columns = results_df.columns[2:]  # Only numerical features
        features = results_df[feature_columns]

        # Standardize the features
        scaler = StandardScaler()
        features_scaled = scaler.fit_transform(features)

        # Apply PCA
        pca_result, explained_variance, components = apply_pca(features_scaled, n_components=3)

        # Add PCA components to DataFrame
        results_df['PCA Component 1'] = pca_result[:, 0]
        results_df['PCA Component 2'] = pca_result[:, 1]
        results_df['PCA Component 3'] = pca_result[:, 2]

        # 3D Visualization of PCA results
        fig = plt.figure(figsize=(10, 8))
        ax = fig.add_subplot(111, projection='3d')
        scatter = ax.scatter(results_df['PCA Component 1'], results_df['PCA Component 2'],
                             results_df['PCA Component 3'],
                             c=np.arange(len(results_df)), cmap='viridis', s=50)
        ax.set_xlabel('PCA Component 1')
        ax.set_ylabel('PCA Component 2')
        ax.set_zlabel('PCA Component 3')
        plt.colorbar(scatter, label='Index')
        plt.title(f'3D PCA of Spectral and Temporal Features for {label} Interval')
        plt.show()

        # Find the most contributing features for each PCA component
        component_df = pd.DataFrame(components, columns=feature_columns, index=['PC1', 'PC2', 'PC3'])
        print(f"Top 10 features contributing to each PCA component for {label}:")
        for i in range(3):
            print(f"\nPCA Component {i + 1}:")
            sorted_features = component_df.iloc[i].abs().sort_values(ascending=False)
            top_features = sorted_features.index[:10]  # Now showing top 10 features
            for j in range(10):
                print(f"{j + 1}. {top_features[j]} (Loading: {component_df.iloc[i][top_features[j]]})")

        # Print explained variance
        print(f"\nExplained variance by each component for {label}: {explained_variance}")

if __name__ == "__main__":
    main_with_pca_by_intervals()
